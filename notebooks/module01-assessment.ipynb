{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assessment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5dpj74Hya2q"
      },
      "source": [
        "# Introduction\n",
        "This assignment will test how well you're able to perform various data science-related tasks.\n",
        "\n",
        "Each Problem Group below will center around a particular dataset that you have worked with before.\n",
        "\n",
        "To ensure you receive full credit for a question, make sure you demonstrate the appropriate pandas, altair, or other commands as requested in the provided code blocks.\n",
        "\n",
        "You may find that some questions require multiple steps to fully answer. Others require some mental arithmetic in addition to pandas commands. Use your best judgment.\n",
        "\n",
        "## Submission\n",
        "Each problem group asks a series of questions. This assignment consists of two submissions:\n",
        "\n",
        "1. After completing the questions below, open the Module 01 Assessment Quiz in Canvas and enter your answers to these questions there.\n",
        "\n",
        "2. After completing and submitting the quiz, save this Colab notebook as a GitHub Gist (You'll need to create a GitHub account for this), by selecting `Save a copy as a GitHub Gist` from the `File` menu above.\n",
        "\n",
        "    In Canvas, open the Module 01 Assessment GitHub Gist assignment and paste the GitHub Gist URL for this notebook. Then submit that assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYhh-W3xk4e"
      },
      "source": [
        "## Problem Group 1\n",
        "\n",
        "For the questions in this group, you'll work with the Netflix Movies Dataset found at this url: [https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv](https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kulUs9K7xxB3"
      },
      "source": [
        "### Question 1\n",
        "Load the dataset into a Pandas data frame and determine what data type is used to store the `release_year` feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecSfSVrsxjx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27ddc4e-19e2-497d-a87d-5b5d9ab283cd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "netflix = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv\")\n",
        "\n",
        "netflix.info()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6234 entries, 0 to 6233\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   show_id       6234 non-null   int64 \n",
            " 1   type          6234 non-null   object\n",
            " 2   title         6234 non-null   object\n",
            " 3   director      4265 non-null   object\n",
            " 4   cast          5664 non-null   object\n",
            " 5   country       5758 non-null   object\n",
            " 6   date_added    6223 non-null   object\n",
            " 7   release_year  6234 non-null   int64 \n",
            " 8   rating        6224 non-null   object\n",
            " 9   duration      6234 non-null   object\n",
            " 10  listed_in     6234 non-null   object\n",
            " 11  description   6234 non-null   object\n",
            "dtypes: int64(2), object(10)\n",
            "memory usage: 584.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivpHTGpczpyM"
      },
      "source": [
        "### Question 2\n",
        "Filter your dataset so it contains only `TV Shows`. How many of those TV Shows were rated `TV-Y7`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf6QABfXx5Xh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d16459-cce2-4189-9429-44e1efc8e0f8"
      },
      "source": [
        "filtered_netflix = netflix[netflix[\"rating\"] == \"TV-Y7\"]\n",
        "\n",
        "netflix_shows = filtered_netflix[[\"show_id\", \"type\", \"rating\", \"release_year\"]]\n",
        "\n",
        "netflix_shows_count = netflix_shows.groupby(\"rating\").count()\n",
        "\n",
        "print(netflix_shows_count)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        show_id  type  release_year\n",
            "rating                             \n",
            "TV-Y7       169   169           169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-esock-41eGo"
      },
      "source": [
        "### Question 3\n",
        "Further filter your dataset so it only contains TV Shows released between the years 2000 and 2009 inclusive. How many of *those* shows were rated `TV-Y7`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBNHqCgz0WDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3199736b-6bcd-4541-ff99-74bb1eea3cde"
      },
      "source": [
        "netflix_shows = filtered_netflix[(filtered_netflix[\"release_year\"] >= 2000) & (filtered_netflix[\"release_year\"] <= 2009)]\n",
        "\n",
        "netflix_shows_count = netflix_shows.groupby(\"rating\").count()\n",
        "\n",
        "print(netflix_shows_count)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        show_id  type  title  director  cast  country  date_added  \\\n",
            "rating                                                              \n",
            "TV-Y7        10    10     10         5    10        7          10   \n",
            "\n",
            "        release_year  duration  listed_in  description  \n",
            "rating                                                  \n",
            "TV-Y7             10        10         10           10  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB4zmoJm3XDj"
      },
      "source": [
        "## Problem Group 2\n",
        "\n",
        "For the questions in this group, you'll work with the Cereal Dataset found at this url: [https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv](https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE_TdsHa3sMj"
      },
      "source": [
        "### Question 4\n",
        "After importing the dataset into a pandas data frame, determine the median amount of `protein` in cereal brands manufactured by Kelloggs. (`mfr` code \"K\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBXFGnfP2tfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae073ed-227f-432b-c70c-bbd4a03c1838"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "cereal = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\")\n",
        "\n",
        "kelloggs_cereal = cereal[cereal[\"mfr\"] == \"K\"]\n",
        "\n",
        "median_protein = kelloggs_cereal[\"protein\"].median()\n",
        "\n",
        "print(median_protein)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3del4PC9NJ-"
      },
      "source": [
        "### Question 5\n",
        "In order to comply with new government regulations, all cereals must now come with a \"Healthiness\" rating. This rating is calculated based on this formula:\n",
        "\n",
        "    healthiness = (protein + fiber) / sugar\n",
        "\n",
        "Create a new `healthiness` column populated with values based on the above formula.\n",
        "\n",
        "Then, determine the median healthiness value for only General Mills cereals (`mfr` = \"G\"), rounded to two decimal places."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFx9yvV6LDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b709269-0d9e-4595-c5b9-2b565665ff9d"
      },
      "source": [
        "cereal[\"healthiness\"] = (cereal[\"protein\"] + cereal[\"fiber\"]) / cereal[\"sugars\"]\n",
        "\n",
        "general_mills_cereal = cereal[cereal[\"mfr\"] == \"G\"]\n",
        "\n",
        "median_healthiness = general_mills_cereal[\"healthiness\"].median()\n",
        "\n",
        "median_healthiness = round(median_healthiness, 2)\n",
        "\n",
        "print(median_healthiness)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcuUNAxC-g7c"
      },
      "source": [
        "## Problem Group 3\n",
        "\n",
        "For the questions in this group, you'll work with the Titanic Dataset found at this url: [https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/titanic.csv](https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/titanic.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POOuuXfYAJQK"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "After loading the dataset into a pandas DataFrame, create a new column called `NameGroup` that contains the first letter of the passenger's surname in lower case.\n",
        "\n",
        "Note that in the dataset, passenger's names are provided in the `Name` column and are listed as:\n",
        "\n",
        "    Surname, Given names\n",
        "\n",
        "For example, if a passenger's `Name` is `Braund, Mr. Owen Harris`, the `NameGroup` column should contain the value `b`.\n",
        "\n",
        "Then count how many passengers have a `NameGroup` value of `k`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80gU65-ASFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8aedb9-deb9-4756-fabe-39f78a18db31"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/titanic.csv\")\n",
        "\n",
        "titanic[\"NameGroup\"] = titanic[\"Name\"].str.split(\",\", expand=True)[0].str[0].str.lower()\n",
        "\n",
        "count_k = (titanic[\"NameGroup\"] == \"k\").sum()\n",
        "\n",
        "print(count_k)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E81qACTfAWl2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}